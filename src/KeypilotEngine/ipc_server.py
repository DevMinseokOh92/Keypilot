import socket
import torch
import json
import re
from unsloth import FastLanguageModel
from english_words import get_english_words_set

HOST = '127.0.0.1'
PORT = 5000 
# ì†ë„ì™€ ì˜ì–´ ì‹¤ë ¥ ë°¸ëŸ°ìŠ¤ê°€ ì¢‹ì€ Llama 3.2 ìœ ì§€
MODEL_ID = "meta-llama/Llama-3.2-1B-Instruct"

ENGLISH_WORDS = sorted(list(get_english_words_set(['web2'], lower=False)))

def load_model():
    print(f"ğŸ”„ [Init] {MODEL_ID} ë¡œë”© ì¤‘...")
    model, tokenizer = FastLanguageModel.from_pretrained(
        model_name = MODEL_ID,
        max_seq_length = 2048,
        dtype = None,
        load_in_4bit = True,
    )
    if tokenizer.pad_token is None: tokenizer.pad_token = tokenizer.eos_token
    FastLanguageModel.for_inference(model)
    print("âœ… [Init] ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
    return model, tokenizer

def search_dictionary(prefix, limit=12):
    prefix_lower = prefix.lower()
    results = []
    for word in ENGLISH_WORDS:
        if word.lower().startswith(prefix_lower):
            if word.lower() == prefix_lower: continue
            results.append(word)
            if len(results) >= limit: break
    return results

def run_server():
    model, tokenizer = load_model()
    
    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    server_socket.bind((HOST, PORT))
    server_socket.listen(5)
    server_socket.settimeout(None) 
    
    print(f"ğŸ“¡ [Server] AI ìë™ì™„ì„± ì—”ì§„ ëŒ€ê¸° ì¤‘ ({HOST}:{PORT})")

    while True:
        client_socket = None
        try:
            client_socket, addr = server_socket.accept()
            
            data = client_socket.recv(65536)
            if not data:
                client_socket.close()
                continue
            
            user_input = data.decode('utf-8')
            print(f"ğŸ“© [ì…ë ¥] '{user_input}'")

            candidates = set()
            
            # ê³µë°±ìœ¼ë¡œ ëë‚˜ë©´ 'ë‹¤ìŒ ë‹¨ì–´ ì˜ˆì¸¡', ì•„ë‹ˆë©´ 'í˜„ì¬ ë‹¨ì–´ ì™„ì„±'
            is_next_word_mode = user_input.endswith(" ")
            
            # 1. ì‚¬ì „ ê²€ìƒ‰ (ë‹¨ì–´ ì™„ì„± ëª¨ë“œì¼ ë•Œë§Œ)
            if not is_next_word_mode:
                last_chunk = user_input.split()[-1] if user_input.strip() else ""
                if len(last_chunk) >= 1:
                    dic_results = search_dictionary(last_chunk, limit=8)
                    for word in dic_results:
                        candidates.add(word)

            # 2. AI ì¶”ë¡  (ë¶€ì¡±í•˜ê±°ë‚˜, ë‹¤ìŒ ë‹¨ì–´ ì˜ˆì¸¡ì¼ ë•Œ)
            if len(candidates) < 12 or is_next_word_mode:
                inputs = tokenizer(user_input, return_tensors="pt").to("cuda")
                
                outputs = model.generate(
                    **inputs, 
                    max_new_tokens=10,       # â˜… ìˆ˜ì •: 5 -> 10 (ë‹¨ì–´ ì˜ë¦¼ ë°©ì§€)
                    num_return_sequences=8, 
                    do_sample=True,
                    temperature=0.6,
                    top_k=40,
                    repetition_penalty=1.2,  # â˜… ìˆ˜ì •: ì•µë¬´ìƒˆ ë°©ì§€
                    pad_token_id=tokenizer.eos_token_id
                )
                
                for output in outputs:
                    generated_text = tokenizer.decode(output[inputs['input_ids'].shape[1]:], skip_special_tokens=True)
                    
                    # 1. ì•ë’¤ ê³µë°± ì •ë¦¬
                    stripped_text = generated_text.lstrip() 
                    # 2. ì²« ë‹¨ì–´ë§Œ ê°€ì ¸ì˜¤ê¸°
                    first_word = stripped_text.split()[0] if stripped_text else ""
                    # 3. ìˆœìˆ˜ ì•ŒíŒŒë²³ê³¼ í•˜ì´í”ˆ, ì•„í¬ìŠ¤íŠ¸ë¡œí”¼ë§Œ í—ˆìš©
                    clean_word = re.sub(r"[^a-zA-Z\-\']", "", first_word)
                    
                    if not clean_word: continue

                    # â˜… [ìˆ˜ì •] 1ê¸€ì í•„í„°ë§ (a, I ì œì™¸í•˜ê³  ë‹¤ ë²„ë¦¼)
                    if len(clean_word) == 1 and clean_word not in ["a", "I"]:
                        continue

                    if is_next_word_mode:
                        # "I want " -> "to"
                        candidates.add(clean_word)
                    else:
                        # "wa" -> "want"
                        last_chunk = user_input.split()[-1]
                        if clean_word.lower().startswith(last_chunk.lower()):
                             candidates.add(clean_word)
                        else:
                             candidates.add(last_chunk + clean_word)

            # 3. ì •ë ¬ ë° ì „ì†¡
            # ê¸¸ì´ ìˆœì„œëŒ€ë¡œ ì •ë ¬í•˜ë˜, ë„ˆë¬´ ê¸´ ë‹¨ì–´(20ì ì´ìƒ)ëŠ” ë’¤ë¡œ ë³´ëƒ„
            final_list = sorted(list(candidates), key=lambda x: (len(x) > 20, len(x)))[:12]
            
            json_response = json.dumps(final_list)
            print(f"ğŸ“¤ [ì „ì†¡] {json_response}")
            
            client_socket.sendall(json_response.encode('utf-8'))

        except Exception as e:
            print(f"âš ï¸ ì—ëŸ¬: {e}")
        finally:
            if client_socket: client_socket.close()

if __name__ == "__main__":
    run_server()